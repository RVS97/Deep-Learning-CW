{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearningImprovedFinal.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RVS97/keras_triplet_descriptor/blob/master/DeepLearningImprovedFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "iamuRgeiNLjW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Safety Check\n"
      ]
    },
    {
      "metadata": {
        "id": "ZZG4BqkENEyd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Taken from\n",
        "# https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# Colab only provides one GPU and it is not always guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BBvIvBoyg68g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h6NNelMhBKMi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Connect to drive"
      ]
    },
    {
      "metadata": {
        "id": "hPKSX3LMBJYP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "rootDir = \"/content/gdrive/My\\ Drive/Colab\\ Notebooks/pickles/Improved\"\n",
        "\n",
        "def saveFile(filePath, rootDir):\n",
        "  !cp $filePath $rootDir\n",
        "  \n",
        "def getFile(fileName, rootDir, localDir = \"./\"):\n",
        "  path = rootDir + \"/\" + fileName\n",
        "  !cp $path $localDir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OMiynJ7p-zI8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Downloading Functions and Data\n",
        "\n",
        "The first step is to clone the GitHub repository of the course, which contains already implemented functions. You can use your own function and import them here doing the same. In addition, we are going to download and extract the N-HPatches data. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "yV1m-9ZGuKGj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Clone repo\n",
        "!git clone https://github.com/MatchLab-Imperial/keras_triplet_descriptor\n",
        "  \n",
        "# If using data augmentation uncomment below, clone personal repository with modiifed class\n",
        "# !git clone https://RVS97:f2de8ab2f114ce7b10d6fdc8097f82ca001bc65a@github.com/RVS97/keras_triplet_descriptor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pyZSqhZ5LACT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Change directory\n",
        "%cd /content/keras_triplet_descriptor    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "307CBCL-FjX4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Download data\n",
        "!wget -O hpatches_data.zip https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "36mBTFvPCxY9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract data\n",
        "!unzip -q ./hpatches_data.zip\n",
        "!rm ./hpatches_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rjyr96hR_4wS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Importing Necessary Modules\n",
        "\n",
        "We now import the modules we will use in this baseline code. "
      ]
    },
    {
      "metadata": {
        "id": "o0KYfe-at9KN",
        "colab_type": "code",
        "outputId": "01d735e7-dbb6-4341-b396-76387f2ad699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Conv2DTranspose\n",
        "from keras.layers import Input, UpSampling2D, concatenate \n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.backend import tf as ktf\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "from read_data import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps\n",
        "from utils import generate_desc_csv, plot_denoise, plot_triplet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "2Y61ZKWZ7o5k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We also fix the seeds of the pseudo-random number generators to have reproducible results. The idea of fixing the seed is having the same results every time the algorithm is run if there are no changes in the code."
      ]
    },
    {
      "metadata": {
        "id": "NXL31ez-AT5h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "random.seed(1234)\n",
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_OqFkNujBGzf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we load the data. The original HPatches dataset has several splits, which are used to separate the available sequences in train sequences and test sequences. For our experiments in N-HPatches we use the same splits as in HPatches. Specifically, we load (and report results) using the split `'a'`:\n"
      ]
    },
    {
      "metadata": {
        "id": "ABKDHB9RApZk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hpatches_dir = './hpatches'\n",
        "splits_path = './splits.json'\n",
        "\n",
        "splits_json = json.load(open(splits_path, 'rb'))\n",
        "split = splits_json['a']\n",
        "\n",
        "train_fnames = split['train']\n",
        "test_fnames = split['test']\n",
        "\n",
        "seqs = glob.glob(hpatches_dir+'/*')\n",
        "seqs = [os.path.abspath(p) for p in seqs]   \n",
        "seqs_train = list(filter(lambda x: x.split('/')[-1] in train_fnames, seqs)) \n",
        "seqs_test = list(filter(lambda x: x.split('/')[-1] in split['test'], seqs)) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qeWik0vMEtuC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models and loss"
      ]
    },
    {
      "metadata": {
        "id": "LYJz8BDzBkIx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now define three functions that define the main modules of our baseline. \n",
        "\n",
        "*   **get_denoise_model(..)** returns the denoising model. The input for the function is the size of the patch, which will be *1x32x32*, and it outputs a keras denoising model. 3 model defined: baseline UNet and UNet with strided and transpose convolutions. \n",
        "*   **get_descriptor_model(..)** builts the descriptor model. The input for the function is the size of the patch, which will be *1x32x32*, and it outputs a keras descriptor model. The model we use as baseline returns a descriptor of dimension *128x1*. 3 models defined: baseline and baseline with dropout, and the VGG implementation.\n",
        "*   **triplet_loss(..)** defines the loss function which is used to train the descriptor model. 3 losses are defined: baseline, in triplet hard mining and colinear approach.\n"
      ]
    },
    {
      "metadata": {
        "id": "W6QbkHnbuIUD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_denoise_model(shape):\n",
        "  \n",
        "  # This is the baseline implementation\n",
        "    \n",
        "  inputs = Input(shape)\n",
        "  \n",
        "  ## Encoder starts\n",
        "  conv1 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  \n",
        "  ## Bottleneck\n",
        "  conv2 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "\n",
        "  ## Now the decoder starts\n",
        "  up3 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv2))\n",
        "  merge3 = concatenate([conv1,up3], axis = -1)\n",
        "  conv3 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge3)\n",
        "    \n",
        "  conv4 = Conv2D(1, 3,  padding = 'same')(conv3)\n",
        "\n",
        "  shallow_net = Model(inputs = inputs, outputs = conv4)\n",
        "  \n",
        "  return shallow_net\n",
        "\n",
        "def get_denoise_model_UNet(shape):\n",
        "\n",
        "  # This is the deeper implementation fo the baseline\n",
        "  \n",
        "  inputs = Input(shape)\n",
        "  \n",
        "  ## Encoder part\n",
        "  conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "  drop2 = Dropout(rate=0.5)(conv2)\n",
        "  pool2 = MaxPooling2D(pool_size=(2, 2))(drop2)\n",
        "  \n",
        "\n",
        "  conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "  drop3 = Dropout(rate=0.5)(conv3)\n",
        "\n",
        "  ## Now the decoder starts\n",
        "  up4 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop3))\n",
        "  merge4 = concatenate([conv2,up4], axis = 3)\n",
        "  conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge4)\n",
        "\n",
        "  up5 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv4))\n",
        "  merge5 = concatenate([conv1,up5], axis = 3)\n",
        "  conv5 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge5)\n",
        "  conv6 = Conv2D(1, 3,  padding = 'same')(conv5)\n",
        "\n",
        "  model = Model(inputs = inputs, outputs = conv6)\n",
        "  \n",
        "  return model\n",
        "\n",
        "def get_denoise_model_UNetConvT(shape):\n",
        "  \n",
        "  # This is the deeper implementation with strided and transposed convolutions\n",
        "    \n",
        "  inputs = Input(shape)\n",
        "  \n",
        "  ## Encoder part: No pooling instead strides of 2\n",
        "  conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "  pool1 = Conv2D(32, 3, strides=(2,2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "  conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "  drop2 = Dropout(rate=0.5)(conv2)\n",
        "  pool2 = Conv2D(64, 3, strides=(2,2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(drop2)  \n",
        "\n",
        "  conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "  drop3 = Dropout(rate=0.5)(conv3)\n",
        "\n",
        "  ## Now the decoder starts: Conv2DTranspose instead of upsampling\n",
        "  up4 = Conv2DTranspose(64, (3, 3), strides=(2, 2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(drop3)\n",
        "  merge4 = concatenate([conv2,up4], axis = 3)\n",
        "  conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge4)\n",
        "\n",
        "  up5 = Conv2DTranspose(32, (3, 3), strides=(2, 2), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "  merge5 = concatenate([conv1,up5], axis = 3)\n",
        "  conv5 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge5)\n",
        "  conv6 = Conv2D(1, 3,  padding = 'same')(conv5)\n",
        "\n",
        "  model = Model(inputs = inputs, outputs = conv6)\n",
        "  \n",
        "  return model\n",
        "\n",
        "\n",
        "def get_descriptor_model(shape):\n",
        "  \n",
        "  '''Architecture copies HardNet architecture'''\n",
        "  \n",
        "  init_weights = keras.initializers.he_normal()\n",
        "  \n",
        "  descriptor_model = Sequential()\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', input_shape=shape, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', strides=2, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', strides=2,  use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "  descriptor_model.add(Dropout(0.3))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 8, padding='valid', use_bias = True, kernel_initializer=init_weights))\n",
        "  \n",
        "  # Final descriptor reshape\n",
        "  descriptor_model.add(Reshape((128,)))\n",
        "  \n",
        "  return descriptor_model\n",
        "\n",
        "def get_descriptor_model_dropout(shape):\n",
        "  \n",
        "  '''Architecture copies HardNet architecture'''\n",
        "  # Dropout layers alternatively to generalise better\n",
        "  \n",
        "  init_weights = keras.initializers.he_normal()\n",
        "  \n",
        "  descriptor_model = Sequential()\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', input_shape=shape, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "  descriptor_model.add(Dropout(0.3))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', strides=2, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "  descriptor_model.add(Dropout(0.3))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', strides=2,  use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "  descriptor_model.add(Dropout(0.3))\n",
        "\n",
        "  descriptor_model.add(Conv2D(256, 8, padding='valid', use_bias = True, kernel_initializer=init_weights))\n",
        "  \n",
        "  # Final descriptor reshape\n",
        "  descriptor_model.add(Reshape((256,)))\n",
        "  \n",
        "  return descriptor_model\n",
        "\n",
        "def get_descriptor_model_VGG(shape):\n",
        "  \n",
        "  # VGG implementation\n",
        "  \n",
        "  # initializer for added layers\n",
        "  init_weights = keras.initializers.he_normal()\n",
        "  \n",
        "  VGG = VGG16(include_top=False, input_shape=(32,32,3), weights='imagenet')\n",
        "  VGGmodel = Model(VGG.input, VGG.layers[9].output)\n",
        "  \n",
        "  # Freeze layers\n",
        "  for layer in VGGmodel.layers:\n",
        "      layer.trainable = False\n",
        "\n",
        "  #resize input for VGG and load layers to model\n",
        "  newInput = Input(shape)\n",
        "  resizedImg = Lambda(lambda image: ktf.image.grayscale_to_rgb(image))(newInput)\n",
        "  VGGvec = VGGmodel(resizedImg)\n",
        "  VGG2 = Model(newInput,VGGvec)\n",
        "  VGGoutput = VGG2.output\n",
        "  \n",
        "  # added layers from now on\n",
        "  output = Conv2D(512,3,strides=2,padding='same',kernel_initializer=init_weights)(VGGoutput)\n",
        "  output = BatchNormalization(axis = -1)(output)\n",
        "  output = Activation('relu')(output)\n",
        "  \n",
        "  output = Conv2D(512,3,padding='same',kernel_initializer=init_weights)(output)\n",
        "  output = BatchNormalization(axis = -1)(output)\n",
        "  output = Activation('relu')(output)\n",
        "  \n",
        "  output = Conv2D(1024,3,strides=2,padding='same',kernel_initializer=init_weights)(output)\n",
        "  output = BatchNormalization(axis = -1)(output)\n",
        "  output = Activation('relu')(output)\n",
        "  \n",
        "  output = Flatten()(output)\n",
        "  output = Dense(128,activation='relu',kernel_initializer=init_weights)(output)\n",
        "  \n",
        "  model = Model(newInput, output)\n",
        "  \n",
        "  return model\n",
        "  \n",
        "def triplet_loss(x):\n",
        "  \n",
        "  # base triplet loss\n",
        "  \n",
        "  output_dim = 128\n",
        "  a, p, n = x\n",
        "  # modify alpha to change triplet margin\n",
        "  _alpha = 1.0\n",
        "  positive_distance = K.mean(K.square(a - p), axis=-1)\n",
        "  negative_distance = K.mean(K.square(a - n), axis=-1)\n",
        "  \n",
        "  # modify following line to change activation function: K.maximum/elu/softplus\n",
        "  return K.expand_dims(K.maximum(0.0, positive_distance - negative_distance + _alpha), axis = 1)\n",
        "\n",
        "def triplet_loss_negative_mining(x):\n",
        "  \n",
        "  output_dim = 128\n",
        "  a, p, n = x\n",
        "  # Vary alpha here\n",
        "  _alpha = 1.0\n",
        "  positive_distance = K.mean(K.square(a - p), axis=-1)\n",
        "  negative_distanceA = K.mean(K.square(a - n), axis=-1)\n",
        "  negative_distanceB = K.mean(K.square(p - n), axis=-1) # compute additional distance\n",
        "  \n",
        "  # find minimum of both distances\n",
        "  negative_distance = K.minimum(negative_distanceA, negative_distanceB)\n",
        "  # modify following line to change activation function: K.maximum/elu/softplus\n",
        "  return K.expand_dims(K.softplus(positive_distance - negative_distance + _alpha), axis = 1)  \n",
        "\n",
        "  \n",
        "def triplet_loss_colinear(x):\n",
        "  \n",
        "  output_dim = 128\n",
        "  a, p, n = x\n",
        "  # Vary alpha here\n",
        "  _alpha = 1.0\n",
        "  ap = a - p\n",
        "  an = a - n\n",
        "  pn = p - n\n",
        "  \n",
        "  # select distance vector according to hard negative mining\n",
        "  v1 = K.switch(K.greater(K.mean(K.l2_normalize(pn)),K.mean(K.l2_normalize(an))),K.l2_normalize(ap),K.l2_normalize(p-a))\n",
        "  v2 = K.switch(K.greater(K.mean(K.l2_normalize(pn)),K.mean(K.l2_normalize(an))),K.l2_normalize(an),K.l2_normalize(pn))\n",
        "  \n",
        "  # inner product of distance vectors\n",
        "  theta = K.sum(v1 * v2,axis=-1)\n",
        "  # hyperparameter\n",
        "  beta = 0.1\n",
        "    \n",
        "  positive_distance = K.mean(K.square(ap), axis=-1)\n",
        "  negative_distanceA = K.mean(K.square(an), axis=-1)\n",
        "  negative_distanceB = K.mean(K.square(pn), axis=-1)\n",
        "  # find minimum of both distances\n",
        "  negative_distance = K.minimum(negative_distanceA, negative_distanceB)\n",
        "  # modify following line to change activation function: K.maximum/elu/softplus\n",
        "  return K.expand_dims(K.softplus(positive_distance - negative_distance + _alpha + beta*theta), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RlS5zcV7EJgp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Denoising Image Patches\n"
      ]
    },
    {
      "metadata": {
        "id": "wHxHwjUd3-pY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "m_VPSHmSK0dS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Uncomment following lines for using all the data to train the denoising model\n",
        "denoise_generator = DenoiseHPatches(seqs_train, batch_size=50)\n",
        "denoise_generator_val = DenoiseHPatches(seqs_test, batch_size=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YOfPqj6p7XOl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Specify denoiser: change function to get baseline, UNet, UNetwithTranpose structures"
      ]
    },
    {
      "metadata": {
        "id": "-eUSba93Dttj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "shape = (32, 32, 1)\n",
        "# modify denoiser function to get desired denoiser structure\n",
        "denoise_model = get_denoise_model(shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OiPGT0BMIoZJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load executed models\n",
        "loadedEpochs = 32\n",
        "modelName = '/content/gdrive/My Drive/Colab Notebooks/pickles/denoiserPython3/denoise'+str(loadedEpochs-1)+'.h5'\n",
        "print(modelName)\n",
        "denoise_model = keras.models.load_model(modelName)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H3wkjkpk4bRh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We set number of epochs to 1, tweak it, along with other hyperparameters, to improve the performance of the model."
      ]
    },
    {
      "metadata": {
        "id": "edwbgE6yKqcD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "sgd = keras.optimizers.SGD(lr=0.00001, momentum=0.9, nesterov=True)\n",
        "# change optimiser to 'adam' if testing adam optimiser\n",
        "denoise_model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mae','mse'])\n",
        "epochs = 32\n",
        "\n",
        "loss = np.zeros((4,epochs))\n",
        "\n",
        "### Use a loop to save for each epoch the weights in an external website in\n",
        "### case colab stops. Every time you call fit/fit_generator the weigths are NOT\n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "for e in range(epochs):\n",
        "    \n",
        "  denoise_history = denoise_model.fit_generator(generator=denoise_generator, \n",
        "                                                epochs=1, verbose=1, \n",
        "                                                validation_data=denoise_generator_val)\n",
        "  \n",
        "  # Define model filenames and save\n",
        "  epochModName = 'denoise'+str(e+loadedEpochs)+'.h5'\n",
        "  print(epochModName)\n",
        "  \n",
        "  print('Finished epoch'+str(e))\n",
        "  \n",
        "  # save loss values in variable\n",
        "  loss[0][e] = denoise_history.history['mean_absolute_error'][0]\n",
        "  loss[1][e] = denoise_history.history['mean_squared_error'][0]\n",
        "  loss[2][e] = denoise_history.history['val_mean_absolute_error'][0]\n",
        "  loss[3][e] = denoise_history.history['val_mean_squared_error'][0]\n",
        "    \n",
        "  ### Saves optimizer and weights\n",
        "  denoise_model.save(epochModName) \n",
        "  \n",
        "  saveFile(epochModName, rootDir)\n",
        "\n",
        "# history filename   \n",
        "epochName = 'denoiserLoss.pkl'\n",
        "\n",
        "# save loss variable\n",
        "with open(epochName,'wb') as f:\n",
        "    pickle.dump(loss,f)\n",
        "\n",
        "saveFile(epochName, rootDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e9FzSZzMEcs4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualization of Denoising Results\n",
        "To visualize how the denoised patches look, you can run the following function. It returns the noisy patch, the denoised patch in the middle, and the clean patch in the right side. "
      ]
    },
    {
      "metadata": {
        "id": "XFA_8uN4Eb3B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_denoise(denoise_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SyABaCvkEPDR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training a Descriptor Network\n"
      ]
    },
    {
      "metadata": {
        "id": "4a6pHRNl8Iiy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Change the model here to use different structures.\n",
        "Change triplet loss here as well to use different triplet loss implementations."
      ]
    },
    {
      "metadata": {
        "id": "DVmDZIRTHPDa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Lambda\n",
        "shape = (32, 32, 1)\n",
        "xa = Input(shape=shape, name='a')\n",
        "xp = Input(shape=shape, name='p')\n",
        "xn = Input(shape=shape, name='n')\n",
        "# modify descriptor model here to define desired structure\n",
        "descriptor_model = get_descriptor_model(shape)\n",
        "ea = descriptor_model(xa)\n",
        "ep = descriptor_model(xp)\n",
        "en = descriptor_model(xn)\n",
        "\n",
        "# change the triplet loss here to do other implementations\n",
        "loss = Lambda(triplet_loss)([ea, ep, en])\n",
        "\n",
        "descriptor_model_trip = Model(inputs=[xa, xp, xn], outputs=loss)\n",
        "sgd = keras.optimizers.SGD(lr=0.1)\n",
        "# Change optimiser to 'adam' to use the Adam optimiser\n",
        "descriptor_model_trip.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['mae','mse'])\n",
        "descriptor_model_trip.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BllXKocHCwZ7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load descriptor generators, set denoise_model=None if not using denoiser (only descriptor). Vary batch size if needed. Uncomment and Set training_generator.transform = True if using data augmentation\n"
      ]
    },
    {
      "metadata": {
        "id": "YIR1cH4fDwKj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Descriptor loading and training\n",
        "# Loading images\n",
        "hPatches = HPatches(train_fnames=train_fnames, test_fnames=test_fnames,\n",
        "                    denoise_model=denoise_model, use_clean=False)\n",
        "# Creating training generator\n",
        "training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=1), num_triplets=100000, batch_size=100)\n",
        "# UNCOMMENT and set to true to allow data augmentation (Make sure using correct repository)\n",
        "# training_generator.transform = False\n",
        "# Creating validation generator\n",
        "val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=0), num_triplets=10000, batch_size=100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GoQYyuD7_4PS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We plot a random triplet in the form of anchor, positive and negative sample. The positive and anchor patches are similar between them (the difference is a geometric transformation, for example rotation), whereas the negative sample should be quite dissimilar to any of the other two."
      ]
    },
    {
      "metadata": {
        "id": "3RQmOMU92csu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_triplet(training_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UaE2_6HUCAOw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now train the descriptor model and save the weights afterward."
      ]
    },
    {
      "metadata": {
        "id": "QPyc8as42WTQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load executed model defining number of epochs executed\n",
        "\n",
        "epochs = 20\n",
        "loadedEpochs = 20\n",
        "\n",
        "modelName = '/content/gdrive/My Drive/Colab Notebooks/pickles/Improved/descriptor'+str(loadedEpochs-1)+'.h5'\n",
        "\n",
        "print(modelName)\n",
        "\n",
        "### As with the denoising model, we use a loop to save for each epoch \n",
        "## #the weights in an external website in case colab stops. \n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "### If you have a model saved from a previous training session\n",
        "### Load it in the next line\n",
        "#descriptor_model_trip = keras.models.load_model(modelName)\n",
        "descriptor_model_trip.set_weights(keras.models.load_model(modelName).get_weights())\n",
        "descriptor_model_trip.optimizer = keras.models.load_model(modelName).optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eiMJf1Cu9OAk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Execute below if new model"
      ]
    },
    {
      "metadata": {
        "id": "xUio-Ci6jkJe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "loadedEpochs = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qn5XTx59U951",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss = np.zeros((4,epochs))\n",
        "for e in range(epochs):\n",
        "  descriptor_history = descriptor_model_trip.fit_generator(generator=training_generator, epochs=1, verbose=1, validation_data=val_generator)\n",
        "  \n",
        "  print('Finished epoch'+str(e))\n",
        "  \n",
        "  #define model and history filename and save\n",
        "  epochModName = 'descriptor'+str(e+loadedEpochs)+'Beta2.h5'\n",
        "  print(epochModName)\n",
        "  \n",
        "  # save loss history in variable\n",
        "  loss[0][e] = descriptor_history.history['mean_absolute_error'][0]\n",
        "  loss[1][e] = descriptor_history.history['mean_squared_error'][0]\n",
        "  loss[2][e] = descriptor_history.history['val_mean_absolute_error'][0]\n",
        "  loss[3][e] = descriptor_history.history['val_mean_squared_error'][0]\n",
        "    \n",
        "  ### Saves optimizer and weights\n",
        "  descriptor_model_trip.save(epochModName) \n",
        "  \n",
        "  saveFile(epochModName, rootDir)\n",
        "\n",
        "# save loss history\n",
        "epochName = 'descLossSpecialBeta2.pkl'\n",
        "\n",
        "with open(epochName,'wb') as f:\n",
        "    pickle.dump(loss,f)\n",
        "\n",
        "saveFile(epochName, rootDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NJ-r9D4hDxij",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generating descriptors files for test data \n",
        "\n",
        "To evaluate the performance of out model we will use an existing evaluation code, which is called HPatches benchmark. HPatches benchmark takes as input the descriptors for the test data in a CSV form. So the whole pipeline is represented in the following image.\n",
        "\n",
        "![](https://i.ibb.co/WcDDf3q/Screenshot-from-2019-02-15-11-17-24.png)\n",
        "\n",
        "This function generates those files by passing it a descriptor model and a denoising model. It performs a first step of denoising the patches, and a second one of computing the descriptor of the denoised patch. If no denoising model is given (variable set to `None`), the descriptor is computed directly in the noisy patch.\n",
        "\n",
        "Similarly to the loading data part, you have the denoise_model variable and `use_clean` variable. If `use_clean` is set to True, the CSV generated will be those of the clean patches, even if a denoising model is given. If set to False, then depends on the variable `denoise_model`. If there is no denoise model (`denoise_model=None`), then it will use the noisy patches. If you give a denoising model, then it will compute the CSV for the denoised patches. This can be useful to explore different scenarios (for example, the Upper Bound can be training the descriptor network with clean patches, and testing with clean patches), however you should always report the score when using noisy patches (depending on the approach you develop, you may want to denoise them or not). The official baseline uses the denoised patches. "
      ]
    },
    {
      "metadata": {
        "id": "kiJb2XDG9bsJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generate_desc_csv(descriptor_model, seqs_test, denoise_model=denoise_model, use_clean=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s0jFr05rE1oI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluating descriptors in HPatches Benchmark\n",
        "We use HPatches benchmark code to compute the results for our model. \n",
        "\n",
        "**Updated**: The necessary code is included in the repository we cloned at the beginning of the code, so we do not need to download any extra data. Also, we simplified the results, so now they only return one value for each of the three tasks."
      ]
    },
    {
      "metadata": {
        "id": "YvOGRh3sc9Wo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we will perform the evaluation of three different tasks (Verification, Matching and Evaluation) using the CSV files we generated as input and the `hpatches_eval.py` script. We also print the results using the `hpatches_results.py` script. The scripts will return a score for each of the tasks. The metric used is called mean Average Precision, which it uses the Precision of the model. The Precision is defined, for a given number of retrieved elements, as the ratio of correct retrieved elements / number of retrieved elements. [Link to Wikipedia with Precision explanation](https://en.wikipedia.org/wiki/Precision_and_recall). The definition of the three different tasks is taken from the [HPatches paper](https://arxiv.org/pdf/1704.05939.pdf).\n",
        "\n",
        "In all of the tasks if you use the optional argument `--more_info` in `hpatches_results.py` you can see extra mAP information. However, the important score is the mAP score reported without this flag.\n",
        "\n",
        "### Verification\n",
        "\n",
        "Patch verification measures the ability of a descriptor to classify whether two patches are extracted from the same measurement. Now we compute the score of our architecture in this task.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Awnyv4xTYSFH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=verification --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=verification --more_info\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5290Bw-udJdr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Matching\n",
        "Image matching, tests to what extent a descriptor can correctly identify correspondences in two images."
      ]
    },
    {
      "metadata": {
        "id": "EUqpwi87ckJv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=matching --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=matching --more_info\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RXXgbN7DdMnx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Retrieval\n",
        "Retrieval tests how well a descriptor can match a query patch to a pool of patches extracted from many images."
      ]
    },
    {
      "metadata": {
        "id": "ZNmKIat1cn_M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=retrieval --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=retrieval --more_info"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8_2fBzUB5RF2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Compressing and saving the CSV files \n",
        "\n",
        "This is not necessary for the analysis of the baseline code included in the report. However, we will be hosting a competition in an external website to see who can achieve the highest score. In that case, you will need to submit the CSV files, as the scoring script will be performed in an external server. With that aim, we include here a way to save the files either in your local disc or in your google drive account.\n",
        "\n",
        "We first compress the directory with all the CSV by using the following command. Remove the `q` option if you want it to output the progress."
      ]
    },
    {
      "metadata": {
        "id": "Lh_svT3p5Ww-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!zip -rq descriptors.zip ./out/custom"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "svoL779J8AJK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The generated .zip is quite large, the method we used for the weights does not work. We have two other methods. First, in the file explorer in the left column we can right-click in the file and then click download. Then, we will see a circle next to the file showing the download progress.\n",
        "\n",
        "The second way does not require for you to download the files, it save the zip file in your Google Drive account, and you can download it later to your machine if you want. To do so, follow this method (found [here](https://stackoverflow.com/questions/49428332/how-to-download-large-files-like-weights-of-a-model-from-colaboratory)). First run the next cell, and the output will be a link for authentication purposes, and just follow the instructions"
      ]
    },
    {
      "metadata": {
        "id": "RjOmPv5z7Opx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "def save_file_to_drive(name, path):\n",
        "  file_metadata = {\n",
        "    'name': name,\n",
        "    'mimeType': 'application/octet-stream'\n",
        "  }\n",
        "\n",
        "  media = MediaFileUpload(path, \n",
        "                          mimetype='application/octet-stream',\n",
        "                          resumable=True)\n",
        "\n",
        "  created = drive_service.files().create(body=file_metadata,\n",
        "                                  media_body=media,\n",
        "                                  fields='id').execute()\n",
        "\n",
        "  print('File ID: {}'.format(created.get('id')))\n",
        "\n",
        "  return created\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YfzjfMc59NKm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can use the following function to save the file to your drive account. The second argument is the name of the file we want to save, and the first argument the name that will have in your Drive."
      ]
    },
    {
      "metadata": {
        "id": "UwrqWr_c7pAi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_file_to_drive('descriptors_save.zip', 'descriptors.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}